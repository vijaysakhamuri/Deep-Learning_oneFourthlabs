{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PeozigfFQ850"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "#For converting the dataset to torchvision dataset format\n",
    "class VowelConsonantDataset(Dataset):\n",
    "    def __init__(self, file_path,train=True,transform=None):\n",
    "        self.transform = transform\n",
    "        self.file_path=file_path\n",
    "        self.train=train\n",
    "        self.file_names=[file for _,_,files in os.walk(self.file_path) for file in files]\n",
    "        self.len = len(self.file_names)\n",
    "        if self.train:\n",
    "            self.classes_mapping=self.get_classes()\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_name=self.file_names[index]\n",
    "        image_data=self.pil_loader(self.file_path+\"/\"+file_name)\n",
    "        if self.transform:\n",
    "            image_data = self.transform(image_data)\n",
    "        if self.train:\n",
    "            file_name_splitted=file_name.split(\"_\")\n",
    "            Y1 = self.classes_mapping[file_name_splitted[0]]\n",
    "            Y2 = self.classes_mapping[file_name_splitted[1]]\n",
    "            z1,z2=torch.zeros(10),torch.zeros(10)\n",
    "            z1[Y1-10],z2[Y2]=1,1\n",
    "            label=torch.stack([z1,z2])\n",
    "\n",
    "            return image_data, label\n",
    "\n",
    "        else:\n",
    "            return image_data, file_name\n",
    "          \n",
    "    def pil_loader(self,path):\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "\n",
    "      \n",
    "    def get_classes(self):\n",
    "        classes=[]\n",
    "        for name in self.file_names:\n",
    "            name_splitted=name.split(\"_\")\n",
    "            classes.extend([name_splitted[0],name_splitted[1]])\n",
    "        classes=list(set(classes))\n",
    "        classes_mapping={}\n",
    "        for i,cl in enumerate(sorted(classes)):\n",
    "            classes_mapping[cl]=i\n",
    "        return classes_mapping\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJJ_MrEVQ_eX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-BX7SIgS_bU"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2cOje6hS_yA"
   },
   "outputs": [],
   "source": [
    "full_data = VowelConsonantDataset(\"../input/train/train\",train=True,transform=transform)\n",
    "train_size = int(0.9 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "\n",
    "train_data, validation_data = random_split(full_data, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=60, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=60, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uzv8q9j63A_L"
   },
   "outputs": [],
   "source": [
    "test_data = VowelConsonantDataset(\"../input/test/test\",train=False,transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=60,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l0HVEsRCBvjb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch Data Loader Code for Vowel Consonant Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
